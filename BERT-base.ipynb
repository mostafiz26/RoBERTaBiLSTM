{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qY731x6gCqnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ],
      "metadata": {
        "id": "PWzjA2GOCqk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_U-J0MRB7ra"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os\n",
        "import pandas as pd\n",
        "from transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\n",
        "from torch.utils.data import Dataset\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "aQiM_VKrB8im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/Dataset/tweets.csv\"\n",
        "#df_org= pd.read_csv(\"Sentiment Analysis Dataset.csv\", encoding='ISO-8859-1')\n",
        "df_org=pd.read_csv(path)\n",
        "#df_org = df_org.sample(frac=1.0, random_state=42)\n",
        "\n",
        "df_org.head()"
      ],
      "metadata": {
        "id": "NAGAAhXCB8f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df_org['sentiment'].unique().tolist()\n",
        "labels"
      ],
      "metadata": {
        "id": "TvcNpxlnB8dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS= len(labels)\n",
        "\n",
        "id2label={id:label for id,label in enumerate(labels)}\n",
        "\n",
        "label2id={label:id for id,label in enumerate(labels)}\n",
        "\n",
        "label2id"
      ],
      "metadata": {
        "id": "ocdQZD1lB8a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_org[\"labels\"]=df_org.sentiment.map(lambda x: label2id[x.strip()])\n",
        "df_org.head()\n"
      ],
      "metadata": {
        "id": "K-7C4hRDB8Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_org.sentiment.value_counts().plot(kind='pie', figsize=(5,5))"
      ],
      "metadata": {
        "id": "iP2yXYisB8Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\", max_length=512)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "cO0kSO54CPJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE= df_org.shape[0]\n",
        "\n",
        "train_texts= list(df_org.review[:(9*SIZE)//10])\n",
        "\n",
        "val_texts=   list(df_org.review[(9*SIZE)//10:(95*SIZE)//100 ])\n",
        "\n",
        "test_texts=  list(df_org.review[(95*SIZE)//100:])\n",
        "\n",
        "train_labels= list(df_org.labels[:(9*SIZE)//10])\n",
        "\n",
        "val_labels=   list(df_org.labels[(9*SIZE)//10:(95*SIZE)//100])\n",
        "\n",
        "test_labels=  list(df_org.labels[(95*SIZE)//100:])\n",
        "\n",
        "len(train_texts), len(val_texts), len(test_texts)"
      ],
      "metadata": {
        "id": "YaqtGCvNCPGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "qxYjuIlwCPD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset class for handling tokenized text data and corresponding labels.\n",
        "    Inherits from torch.utils.data.Dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "        \"\"\"\n",
        "        Initializes the DataLoader class with encodings and labels.\n",
        "\n",
        "        Args:\n",
        "            encodings (dict): A dictionary containing tokenized input text data\n",
        "                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n",
        "            labels (list): A list of integer labels for the input text data.\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the data item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            item (dict): A dictionary containing the tokenized data and the corresponding label.\n",
        "        \"\"\"\n",
        "        # Retrieve tokenized data for the given index\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # Add the label for the given index to the item dictionary\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of data items in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            (int): The number of data items in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "YP1DSjL7CPBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels)"
      ],
      "metadata": {
        "id": "jfEJ4ua4B8Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_encodings, train_labels)\n",
        "\n",
        "val_dataloader = DataLoader(val_encodings, val_labels)\n",
        "\n",
        "test_dataset = DataLoader(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "3UdOC40ACZf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "-qyOl3FQCZdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy, F1, precision, and recall for a given set of predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (obj): An object containing label_ids and predictions attributes.\n",
        "            - label_ids (array-like): A 1D array of true class labels.\n",
        "            - predictions (array-like): A 2D array where each row represents\n",
        "              an observation, and each column represents the probability of\n",
        "              that observation belonging to a certain class.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the following metrics:\n",
        "            - Accuracy (float): The proportion of correctly classified instances.\n",
        "            - F1 (float): The macro F1 score, which is the harmonic mean of precision\n",
        "              and recall. Macro averaging calculates the metric independently for\n",
        "              each class and then takes the average.\n",
        "            - Precision (float): The macro precision, which is the number of true\n",
        "              positives divided by the sum of true positives and false positives.\n",
        "            - Recall (float): The macro recall, which is the number of true positives\n",
        "              divided by the sum of true positives and false negatives.\n",
        "    \"\"\"\n",
        "    # Extract true labels from the input object\n",
        "    labels = pred.label_ids\n",
        "\n",
        "    # Obtain predicted class labels by finding the column index with the maximum probability\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "\n",
        "    # Calculate the accuracy score using sklearn's accuracy_score function\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Return the computed metrics as a dictionary\n",
        "    return {\n",
        "        'Accuracy': acc,\n",
        "        'F1': f1,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall\n",
        "    }\n"
      ],
      "metadata": {
        "id": "4BuebvR2CZa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    # The output directory where the model predictions and checkpoints will be written\n",
        "    output_dir='./SentimentAnaTwitter',\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    #  The number of epochs, defaults to 3.0\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    # Number of steps used for a linear warmup\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=1e-5,\n",
        "    logging_strategy='steps',\n",
        "   # TensorBoard log directory\n",
        "    logging_dir='./multi-class-logs',\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ],
      "metadata": {
        "id": "SH7dU1HVCZYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with training_args.strategy.scope():\n",
        "# model = TFDistilBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    # the pre-trained model that will be fine-tuned\n",
        "    model=model,\n",
        "     # training arguments that we defined above\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataloader,\n",
        "    eval_dataset=val_dataloader,\n",
        "    compute_metrics= compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "CkSgdJ8mCZRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "krsHSLI7CZOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n",
        "\n",
        "pd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]"
      ],
      "metadata": {
        "id": "fxFKq-JbCZKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T50FF69FB8PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}